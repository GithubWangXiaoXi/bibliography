%# -*- coding: utf-8-unix -*-
%%==================================================
\chapter{多任务联合学习}

\section{Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics}

论文地址: \href{https://arxiv.org/abs/1705.07115v3}{Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics}

参考资料: \href{https://blog.csdn.net/cdknight_happy/article/details/102618883}{多任务损失优化1}，\href{https://blog.csdn.net/qq_41214679/article/details/110750812}{多任务损失优化2}

\subsection{问题提出}

\subsubsection{多任务学习介绍}

以前多任务的总损失函数可用如下表达式表示
\begin{align}
& L_{total} = \sum_i w_iL_i
\end{align}

只是简单的对每个子任务进行线性求和，这样会存在很多问题，例如模型对于权重参数很敏感，如下图\href{fig:1-1}{1-1}所示
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=4.5in]{figure/example/2.png}\\
  \caption{不同任务对权重参数很敏感}
  \label{fig:1-1}
\end{figure}

\subsubsection{本文创新点}

多任务联合学习可以提升各任务的学习效果，因为多任务可以共享数据集、共享低层特征。但多任务联合学习时，该如何对各子任务的损失函数进行加权才能取得最优的训练效果，这是本文所关心的问题。

本文中作者提出的多任务如下图\href{fig:1-2}{1-2}所示：
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=4.5in]{figure/example/1.png}\\
  \caption{论文中用到的多任务图}
  \label{fig:1-2}
\end{figure}

本论文创新点：
\begin{enumerate}
    \item 利用同方差不确定性同时学习不同数量和单元的分类和回归损失的一种新颖多任务损失
    \item 建立统一的组合语义分割、定位分割和深度回归体系结构
    \item 证明模型损失权重的重要性，并且能够解决并获得良好的参数。
\end{enumerate}

\subsection{解决方案}

\subsubsection{同方差不确定性}

在贝叶斯建模中，需要解决两种不同类型的不确定性。
\begin{enumerate}
    \item 认知不确定性：表示的是模型本身的不确定性，这是因为缺乏训练数据，模型认知不足，可以通过扩充训练集进行解决；
    \item 偶然不确定性：偶然不确定性表示数据不能解释的信息。
\end{enumerate}

偶然不确定性又分成两类：
\begin{enumerate}
    \item 数据依赖(异方差)不确定性：依赖于输入数据的不确定性，体现在模型的输出上。
    \item 任务依赖(同方差)不确定性：不取决于输入数据，而是取决于不同的任务。
\end{enumerate}

在多任务联合学习中，任务依赖不确定性能够表示不同任务间的相对难度，下面证明在多任务学习中可以通过通过任务依赖不确定性对不同的损失进行加权。

\subsubsection{多任务似然}
下面通过最大化同方差不确定性的最大高斯似然推导多任务损失函数。

假设输入为X，参数矩阵为W，输出为$f^W(x)$。

1、对于回归任务，定义其概率为以输出为均值的高斯似然，即
\begin{align}
& p(y|f^W(x)) = N(f^W(x),\sigma^2)
\end{align}

2、对于分类任务，定义：
\begin{align}
& p(y|f^W(x)) = Softmax(f^W(x))
\end{align}

3、多任务模型，其似然为：
\begin{align}
& p(y_1,...,y_k|f^W(x)) = p(y_1|f^W(x))...p(y_K|f^W(x))
\end{align}

其中

正态分布的概率密度函数为
\begin{align}
& f(x) = \frac{1}{\sqrt{2 \pi}\sigma}exp(-\frac{(x - \mu)^2}{2\sigma^2})
\end{align}

Softmax表达式为
\begin{align}
& softmax(X)_{ij} = \frac{exp(X_{ij})}{\sum_k exp(X_{ik})}
\end{align}

\subsubsection{回归任务}

对于回归任务，即公式(2)，其对数似然为：
\begin{align}
&\log p(y|f^W(x)) \propto - \frac{1}{2\sigma^2}||y - f^W(x)||^2 - log \sigma
\end{align}

对于高斯似然，$\sigma$为模型的观测噪声参数，表示输出数据中的噪声量。我们的目的是基于参数矩阵$W$和标准差$\sigma$最大化对数似然。

假设多任务模型进行两个回归任务，两个任务都符合高斯分布，输出分别是 $y_1$和$y_2$，那么总的对数似然为：
\begin{align}
&p(y_1,y_2 | f^w(x)) = p(y_1|f^W(x))p(y_2|f^W(x)) \nonumber \\
&= N(y_1;f^W(x),\sigma^2_1)N(y_2;f^W(x),\sigma^2_2)
\end{align}

取对数，优化目标变成了最大化对数似然，也是最小化负对数似然，即：
\begin{align}
& = -\log p(y_1,y_2 | f^W(x)) \nonumber \\
&\propto \frac{1}{2\sigma^2_1}||y_1 - f^W(x)||^2 + \frac{1}{2\sigma^2_2}||y_2 - f^W(x)||^2 + \log \sigma_1 \sigma_2 \nonumber \\
& = \frac{1}{2\sigma^2_1}L_1(w) + \frac{1}{2\sigma^2_2}L_2(w) + \log \sigma_1 \sigma_2
\end{align}

要是想最小化负对数似然，就需要调整$\sigma_1$ 和 $\sigma_2$的值。 $\sigma_1$ 增加，$L_1(w)$会减小，反之亦然。最后项影响不大，可以当作正则化项。

\subsubsection{分类任务}

对于分类任务的概率，添加一个标量缩放系数$\sigma^2$
\begin{align}
&p(y|f^W(x),\sigma) = Softmax(\frac{1}{\sigma^2}f^W(x))
\end{align}

这被称作是Boltzmann分布，也叫做吉布斯分布。系数$\sigma^2$可以是设定的，也可以是通过学习得到的，决定离散分布的平坦程度。该值和分布的不确定性(熵)有关。其对数似然可以写成：
\begin{align}
log(y=c|f^W(x),\sigma) = \frac{1}{\sigma^2}f_c^W(x) - log(\sum_{c'}exp(\frac{1}{\sigma^2}f^W_{c'}(x)))
\end{align}

\subsubsection{回归和分类任务}
假设一个多任务模型由一个分类任务和一个回归任务组成，那么联合损失为：
\begin{align}
& = -\log p(y_1,y_2 = c|f^W(x)) \nonumber \\
& = - \log N(y_1;f^W(x),\sigma_1^2) \cdot Softmax(y_2 = c;f^W(x),\sigma_2) \nonumber \\
& = \frac{1}{2\sigma^2_1}||y_1 - f^W(x)||^2 + log\sigma_1 - \log p(y_2 = c | f^W(x),\sigma_2) \nonumber \\
& = \frac{1}{2\sigma^2_1}L_1(W) +\frac{1}{\sigma^2_2}L_2(W)+ \log \sigma_1+ \log\frac{\sum_{c'}exp(\frac{1}{\sigma^2_2}f_{c'}^W(x))}{(\sum_{c'}exp(f_{c'}^W(x))^{\frac{1}{\sigma^2_2}}}\nonumber \\
&\approx \frac{1}{2\sigma_1^2}L_1(W) + \frac{1}{\sigma^2_2}L_2(W)+\log\sigma_1+ \log\sigma_2
\end{align}

上式中，$L_1(W) = || y_1-f^W(x)||^2$，为回归子任务输出和真实label = $y_1$ 间的欧式距离。 $L_2(W)=-\log (Softmax( y_2 , f^W(x)))$是分类子任务的交叉熵损失。优化的目的是同时寻找最优的$W$、$\sigma_1$和$\sigma_2$。

最终的目标可以看成是学习每一个子任务输出的相对权重。大的$\sigma_2$会降低$L_2(W)$的影响，小的$\sigma_2$会增大$L_2(W)$的影响。

作者最终的做法是在模型训练的过程中去优化$\sigma_1$和$\sigma_2$，并且为了提升数值稳定性，作者去学习参数$s:=\log \sigma^2$。


\subsection{实验结果}

实验结果如图\href{fig:1-3}{1-3}所示, 得出的结论是基于三个任务的不确定性进行损失加权的效果最好。
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=4.5in]{figure/example/3.png}\\
  \caption{实验结果图}
  \label{fig:1-3}
\end{figure}

\subsection{补充知识}

\subsubsection{频率派和贝叶斯派}

在概率估计或者机器学习里的参数估计上，有两个方法，MLE（最大似然估计） 和MAP（最大后验估计），其实代表了概率论里的两个派别，频率派和贝叶斯派\footnote{频率派vs贝叶斯派 \quad \url{https://blog.csdn.net/weixin_43593330/article/details/105797717}}。 在了解这两个派别所研究内容有啥区别之前，我们有必要先理清一些基础概念：什么是似然函数，什么是概率函数，什么是MLE，MAP。\\

1、似然函数

在统计学中，假设我们对含未知参数的模型给定一个参数值，似然函数为的是去衡量这个模型对于数据样本的拟合程度。似然函数由样本的联合概率分布构成，并作为关于参数的函数来使用。通过似然函数最大化来获取这些参数，即最大似然估计，为了计算方便，通常使用对数似然函数。在概率论的两个派别中，似然函数都起着基础性的作用。

1、MLE（最大似然估计）

在MLE中，首先要定义可能性函数$$
\begin{align}
& L(\theta|x) = f_D(x_1,x_2,...,x_n|\theta) \nonumber \\
& = \prod_{i = 1}^n p(x_i;\theta)
\end{align}

在$\theta$的所有取值上，使这个函数最大化，这个使可能性最大的值即为MLE（一般求解步骤见百度）。

这里举个例子：假设有一个造币厂生产某种硬币，现在我们拿到了一枚硬币，想试试这硬币是不是均匀的，我们可以通过抛硬币的方式，统计硬币正反面出现的概率（记为$\theta$），如果正反面出现的概率相同，则该硬币是均匀的，反之亦然\footnote{贝叶斯公式理解与应用 \quad \url{https://blog.csdn.net/qq_33934427/article/details/105002894}}。

于是我们拿这枚硬币抛了10次，得到的数据（$x_0$）是："反正正正正反正正正反"，其中正面概率$\theta$是我们想求的模型参数，我们可以得到似然函数
\begin{align}
& f(x_0,\theta)=(1-\theta) \times \theta \times \theta \times \theta \times \theta \times (1-\theta) \times \theta \times \theta \times \theta \times (1-\theta)=\theta^7(1-\theta)^3 = f(\theta)
\end{align}

实验得到的似然函数值为0.7，这能说明该厂生产的硬币是不均匀吗？显然是不行的，实验的次数太少了，如果实验次数达到上千次，正负面统计的频数或许各占一半。\\

2、MAP（最大后验估计）

最大似然估计通过求解参数$\theta$, 使似然函数$P(x0|\theta)$最大。而最大后验概率估计则是在求解$\theta$过程中，使$P(x0|\theta)P(\theta)$最大。要想使后验概率尽可能大，关于$\theta$的似然函数要大，$\theta$自己出现的先验概率也要大。这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法。MAP公式如下

\begin{align}
& P(\theta|x0)=\frac{P(x0|\theta)P(\theta)}{P(x0)}
\end{align}

由于MAP在计算过程中，$x0$是确定的。如果还是拿上面MLE的例子，$x0$ 表示硬币投出正反面数：“反正正正正反正正正反”，假设“投10次硬币”是一次实验，实验做了1000 次，“反正正正正反正正正反”出现了n次，则$P(x0)=n/1000$。因此$P(x0)$是一个已知值，所以在计算MAP时可以去掉分母$P(x0)$

MAP在最大化$P(\theta|x0)$ 的意义也很明确，$x0$已经确定了，求$\theta$ 使$P(\theta|x0)$ 最大。\\

3、概率函数和似然函数

对于如下函数，假设输入有两个：$x$表示某一个具体的数据； $\theta$ 表示模型的参数。
\begin{align}
& P(x|\theta)
\end{align}

若$\theta$是已知确定的，$x$是变量，这个函数叫做概率函数，它描述在给定模型参数$\theta$，对于不同的样本点$x$其出现概率是多少（softmax）。最大后验概率估计目的是求$x$，即
\begin{align}
& p(X|\theta) = \max\{p(x_1 | \theta),p( x_2 | \theta), ... , p( x_3 | \theta)\}
\end{align}

如果$x$是已知确定的，$\theta$是变量，这个函数叫做似然函数，它描述对于不同的模型参数，出现$x$这个样本点的概率是多少。最大似然估计目的是求参数$\theta$，即
\begin{align}
& p(X|\theta) = \max\{p(X | \theta_1),p( X | \theta_2), ... , p( X | \theta_n)\}
\end{align}

如何理解这个函数$P(x|\theta)$

往大的说，这两个派别代表了不同的世界观。频率派认为参数($\theta$) 是客观存在不会改变的，虽然未知，但却是固定值。贝叶斯派则认为参数是随机值，因为不可能做完整的实验去确定，因此参数也可以有分布。

往小处说，频率派最常关心的是似然函数，他们认为直接用样本去计算出的概率就是真实的，而贝叶斯派最常关心的是后验分布，他们认为样本只是用来修正经验观点。

贝叶斯派因为所有的参数都是随机变量，都有分布，因此可以使用一些基于采样的方法 （如MCMC）使得我们更容易构建复杂模型。频率派的优点则是没有假设一个先验分布，因此更加客观，也更加无偏，在一些保守的领域（比如制药业、法律）比贝叶斯方法更受到信任。

本质上MLE是根据样本数据直接计算概率参数，而MAP是预设一个参数的概率分布，然后通过样本数据去进行修正。如果样本量不够大的时候，MAP 可能更符合人们的日常经验，比如一个硬币抛五次，都是正面朝上，那么MLE算出来就是这个硬币正面朝上概率为100$\%$，而用先验概率50$\%$加上MAP去算，可能只是51$\%$，更符合人们的日常经验。

如果样本量足够大，这两个方法还是殊途同归的：假设参数$\theta$表示硬币为正面，$x$是我们在实验中抛硬币时统计的数据，$x$ 中有502次统计为反面，498次统计为正面。根据MLE，求解的最大似然函数为$p(x|\theta) = p(498|\mbox{正面)} \approx 0.5$；根据MAP，求解的最大后验概率为$p(\theta|x) = p(\mbox{正面}|498) \approx \frac{(0.5 * 0.5)}{0.5} = 0.5$

如果样本量适中，那么MAP使用比较合理的先验概率是很重要的


